{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaiky-ferreira/PerceptronAspirador/blob/main/PerceptronAspirador.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKBq_GiMyuwv",
        "outputId": "00eb7342-c071-42ce-dae8-dca18a8f52b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    1/1500 | train MSE: 0.44520 | val MSE: 0.35904\n",
            "Epoch  151/1500 | train MSE: 0.01514 | val MSE: 0.01503\n",
            "Epoch  301/1500 | train MSE: 0.00889 | val MSE: 0.00880\n",
            "Epoch  451/1500 | train MSE: 0.00762 | val MSE: 0.00755\n",
            "Epoch  601/1500 | train MSE: 0.00724 | val MSE: 0.00720\n",
            "Epoch  751/1500 | train MSE: 0.00711 | val MSE: 0.00709\n",
            "Epoch  901/1500 | train MSE: 0.00707 | val MSE: 0.00705\n",
            "Epoch 1051/1500 | train MSE: 0.00705 | val MSE: 0.00704\n",
            "Epoch 1201/1500 | train MSE: 0.00705 | val MSE: 0.00704\n",
            "Early stopping at epoch 1350 (best val MSE: 0.00704).\n",
            "[FINAL] train MSE=0.0070, MAE=0.0586 | val MSE=0.0070, MAE=0.0598\n",
            "\n",
            "Métricas (MSE, MAE):\n",
            "   Treino: (0.007047474067817064, 0.05860346412135196)\n",
            "Validação: (0.007038230400436376, 0.05977081372699358)\n",
            "\n",
            "Demonstração:\n",
            "Entrada: piso=madeira, sujeira=2, dist=5.0 m  ->  velocidade=4.5  potência=1.25\n",
            "Entrada: piso=cerâmica, sujeira=6, dist=2.5 m  ->  velocidade=2.16  potência=1.76\n",
            "Entrada: piso=carpete, sujeira=9, dist=0.5 m  ->  velocidade=1.1  potência=2.61\n",
            "Entrada: piso=carpete, sujeira=3, dist=5.0 m  ->  velocidade=3.23  potência=2.06\n",
            "Entrada: piso=madeira, sujeira=10, dist=0.0 m  ->  velocidade=1.26  potência=1.89\n",
            "Entrada: piso=porcelanato, sujeira=7, dist=4.0 m  ->  velocidade=2.66  potência=1.87\n",
            "Entrada: piso=wood, sujeira=5, dist=2.0 m  ->  velocidade=2.62  potência=1.43\n",
            "Entrada: piso=carpet, sujeira=8, dist=1.0 m  ->  velocidade=1.17  potência=2.54\n",
            "\n",
            "Rodando sanity checks...\n",
            "Sanity checks: OK\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple, List, Optional, Dict\n",
        "import unicodedata\n",
        "\n",
        "\n",
        "# Utilidades e codificação\n",
        "\n",
        "\n",
        "FLOORS = [\"madeira\", \"cerâmica\", \"carpete\"]\n",
        "\n",
        "# Aliases mais robustos; suportamos variações e inglês\n",
        "FLOOR_ALIASES: Dict[str, List[str]] = {\n",
        "    \"madeira\":  [\"madeira\", \"wood\", \"assoalho\", \"laminado\"],\n",
        "    \"cerâmica\": [\"cerâmica\", \"ceramica\", \"tile\", \"ceramic\", \"porcelanato\"],\n",
        "    \"carpete\":  [\"carpete\", \"carpet\", \"tapete\"]\n",
        "}\n",
        "\n",
        "def _strip_accents(s: str) -> str:\n",
        "    return \"\".join(\n",
        "        c for c in unicodedata.normalize(\"NFD\", s)\n",
        "        if unicodedata.category(c) != \"Mn\"\n",
        "    )\n",
        "\n",
        "def canonical_floor_name(raw: str) -> str:\n",
        "    \"\"\"Normaliza e encontra o piso canônico ou lança ValueError.\"\"\"\n",
        "    s = _strip_accents(raw.strip().lower())\n",
        "    for canon, variants in FLOOR_ALIASES.items():\n",
        "        for v in variants:\n",
        "            if _strip_accents(v) == s or s.startswith(_strip_accents(v)):\n",
        "                return canon\n",
        "    raise ValueError(f\"Tipo de piso desconhecido: {raw}. Use um de {FLOORS} (aliases aceitos: {FLOOR_ALIASES})\")\n",
        "\n",
        "def one_hot_floor(floor: str) -> np.ndarray:\n",
        "    f = canonical_floor_name(floor)\n",
        "    vec = np.zeros(3, dtype=float)\n",
        "    idx = [\"madeira\", \"cerâmica\", \"carpete\"].index(f)\n",
        "    vec[idx] = 1.0\n",
        "    return vec\n",
        "\n",
        "def scale_inputs(dirt_0_10: float, dist_0_5m: float) -> Tuple[float, float]:\n",
        "    \"\"\"Normaliza sujeira e distância para [0,1] com limites/clamp.\"\"\"\n",
        "    dirt = max(0.0, min(10.0, float(dirt_0_10))) / 10.0\n",
        "    dist = max(0.0, min(5.0,  float(dist_0_5m)))  / 5.0\n",
        "    return dirt, dist\n",
        "\n",
        "def encode_row(floor: str, dirt: float, dist: float) -> np.ndarray:\n",
        "    fvec = one_hot_floor(floor)\n",
        "    dirt_n, dist_n = scale_inputs(dirt, dist)\n",
        "    return np.concatenate([fvec, [dirt_n, dist_n]])[None, :]  # (1,5)\n",
        "\n",
        "\n",
        "\n",
        "# Ativação (sigmoide limitada) estável\n",
        "\n",
        "\n",
        "def _sigmoid_stable(z: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Sigmoide numericamente estável.\"\"\"\n",
        "    z = np.asarray(z, dtype=float)\n",
        "    out = np.empty_like(z)\n",
        "    pos = z >= 0\n",
        "    neg = ~pos\n",
        "    out[pos] = 1.0 / (1.0 + np.exp(-z[pos]))\n",
        "    ez = np.exp(z[neg])\n",
        "    out[neg] = ez / (1.0 + ez)\n",
        "    return out\n",
        "\n",
        "@dataclass\n",
        "class BoundedSigmoid:\n",
        "    \"\"\"Aceita vetores y_min/y_max para múltiplas saídas.\"\"\"\n",
        "    y_min: np.ndarray  # shape (O,)\n",
        "    y_max: np.ndarray  # shape (O,)\n",
        "\n",
        "    def forward(self, z: np.ndarray) -> np.ndarray:\n",
        "        sig = _sigmoid_stable(z)\n",
        "        return self.y_min + (self.y_max - self.y_min) * sig\n",
        "\n",
        "    def grad(self, z: np.ndarray) -> np.ndarray:\n",
        "        sig = _sigmoid_stable(z)\n",
        "        return (self.y_max - self.y_min) * sig * (1.0 - sig)\n",
        "\n",
        "\n",
        "\n",
        "# Perceptron Multi-Saída (2 saídas: velocidade e sucção)\n",
        "\n",
        "\n",
        "class MultiOutputPerceptron:\n",
        "    \"\"\"\n",
        "    Modelo linear com ativação sigmoide limitada e 2 saídas.\n",
        "    W: (n_features+1, 2) incluindo bias.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_features: int, activation: BoundedSigmoid, seed: int = 42):\n",
        "        self.n_features = n_features\n",
        "        self.activation = activation\n",
        "        rng = np.random.default_rng(seed)\n",
        "        self.W = rng.uniform(-0.5, 0.5, size=(n_features + 1, 2))  # duas saídas\n",
        "\n",
        "    def _add_bias(self, X: np.ndarray) -> np.ndarray:\n",
        "        ones = np.ones((X.shape[0], 1), dtype=float)\n",
        "        return np.hstack([X, ones])\n",
        "\n",
        "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
        "        Xb = self._add_bias(X)              # (N, F+1)\n",
        "        Z  = Xb @ self.W                    # (N, 2)\n",
        "        Y  = self.activation.forward(Z)     # (N, 2)\n",
        "        return Y\n",
        "\n",
        "    @staticmethod\n",
        "    def _mse(y_pred: np.ndarray, y_true: np.ndarray) -> float:\n",
        "        return float(np.mean((y_pred - y_true) ** 2))\n",
        "\n",
        "    @staticmethod\n",
        "    def _mae(y_pred: np.ndarray, y_true: np.ndarray) -> float:\n",
        "        return float(np.mean(np.abs(y_pred - y_true)))\n",
        "\n",
        "    def fit(\n",
        "        self,\n",
        "        X: np.ndarray,\n",
        "        y_true: np.ndarray,              # shape (N, 2)\n",
        "        lr: float = 0.2,\n",
        "        epochs: int = 1000,\n",
        "        verbose: bool = False,\n",
        "        X_val: Optional[np.ndarray] = None,\n",
        "        y_val: Optional[np.ndarray] = None,\n",
        "        patience: int = 50\n",
        "    ):\n",
        "        Xb = self._add_bias(X)            # (N, F+1)\n",
        "        N  = Xb.shape[0]\n",
        "\n",
        "        best_val = np.inf\n",
        "        best_W = self.W.copy()\n",
        "        no_improve = 0\n",
        "\n",
        "        for ep in range(epochs):\n",
        "            Z      = Xb @ self.W                          # (N,2)\n",
        "            y_pred = self.activation.forward(Z)           # (N,2)\n",
        "            dAct   = self.activation.grad(Z)              # (N,2)\n",
        "\n",
        "            # Gradiente MSE médio por amostra e por saída\n",
        "            dL_dZ  = (2.0 / N) * (y_pred - y_true) * dAct # (N,2)\n",
        "            grad_W = Xb.T @ dL_dZ                         # (F+1,2)\n",
        "            self.W -= lr * grad_W\n",
        "\n",
        "            # Early stopping (se houver validação)\n",
        "            if X_val is not None and y_val is not None:\n",
        "                y_val_pred = self.predict(X_val)\n",
        "                val_loss = self._mse(y_val_pred, y_val)\n",
        "                if val_loss + 1e-10 < best_val:\n",
        "                    best_val = val_loss\n",
        "                    best_W = self.W.copy()\n",
        "                    no_improve = 0\n",
        "                else:\n",
        "                    no_improve += 1\n",
        "\n",
        "                if verbose and (ep % max(1, epochs // 10) == 0 or ep == epochs - 1):\n",
        "                    tr_loss = self._mse(y_pred, y_true)\n",
        "                    print(f\"Epoch {ep+1:4d}/{epochs} | train MSE: {tr_loss:.5f} | val MSE: {val_loss:.5f}\")\n",
        "\n",
        "                if no_improve >= patience:\n",
        "                    if verbose:\n",
        "                        print(f\"Early stopping at epoch {ep+1} (best val MSE: {best_val:.5f}).\")\n",
        "                    break\n",
        "            else:\n",
        "                if verbose and (ep % max(1, epochs // 10) == 0 or ep == epochs - 1):\n",
        "                    tr_loss = self._mse(y_pred, y_true)\n",
        "                    print(f\"Epoch {ep+1:4d}/{epochs} | train MSE: {tr_loss:.5f}\")\n",
        "\n",
        "        # Restaura os melhores pesos (validação)\n",
        "        if X_val is not None and y_val is not None:\n",
        "            self.W = best_W\n",
        "\n",
        "    # Utilitários de métricas públicas\n",
        "    def evaluate(self, X: np.ndarray, y_true: np.ndarray) -> Tuple[float, float]:\n",
        "        y_pred = self.predict(X)\n",
        "        return self._mse(y_pred, y_true), self._mae(y_pred, y_true)\n",
        "\n",
        "\n",
        "\n",
        "# Heurística-alvo e dataset\n",
        "\n",
        "\n",
        "def target_speed_and_suction(floor_vec: np.ndarray, dirt_n: float, dist_n: float) -> Tuple[float, float]:\n",
        "    \"\"\"Retorna (speed[1,5], suction[1,3]) conforme heurísticas simples.\"\"\"\n",
        "    wood, ceramic, carpet = floor_vec\n",
        "    suction_floor = 0.0 * wood + 0.3 * ceramic + 1.0 * carpet\n",
        "    speed_floor_penalty = 0.0 * wood + 0.3 * ceramic + 0.8 * carpet\n",
        "    suction = 1.0 + 0.9 * dirt_n + 0.8 * suction_floor\n",
        "    suction = float(np.clip(suction, 1.0, 3.0))\n",
        "    speed = 5.0 - 2.0 * dirt_n - 2.2 * (1.0 - dist_n) - 1.5 * speed_floor_penalty\n",
        "    speed = float(np.clip(speed, 1.0, 5.0))\n",
        "    return speed, suction\n",
        "\n",
        "def make_dataset(n_samples: int = 1500, seed: int = 777):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    X_list, y_list = [], []\n",
        "    for _ in range(n_samples):\n",
        "        floor = rng.choice(FLOORS)\n",
        "        dirt  = rng.uniform(0, 10)\n",
        "        dist  = rng.uniform(0, 5)\n",
        "        fvec = one_hot_floor(floor)\n",
        "        dirt_n, dist_n = scale_inputs(dirt, dist)\n",
        "        x = np.concatenate([fvec, [dirt_n, dist_n]])\n",
        "        speed, suction = target_speed_and_suction(fvec, dirt_n, dist_n)\n",
        "        X_list.append(x)\n",
        "        y_list.append([speed, suction])\n",
        "    X = np.array(X_list, dtype=float)           # (N,5)\n",
        "    Y = np.array(y_list, dtype=float)           # (N,2)\n",
        "    return X, Y\n",
        "\n",
        "def train_val_split(X: np.ndarray, Y: np.ndarray, val_ratio: float = 0.2, seed: int = 2024):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    N = X.shape[0]\n",
        "    idx = rng.permutation(N)\n",
        "    n_val = int(round(val_ratio * N))\n",
        "    val_idx = idx[:n_val]\n",
        "    tr_idx  = idx[n_val:]\n",
        "    return X[tr_idx], Y[tr_idx], X[val_idx], Y[val_idx]\n",
        "\n",
        "\n",
        "\n",
        "# Treino, salvar, carregar, predição\n",
        "\n",
        "\n",
        "WEIGHTS_PATH = \"vacuum_multi.npz\"\n",
        "\n",
        "def train_model(verbose: bool = False):\n",
        "    X, Y = make_dataset(n_samples=2000, seed=777)\n",
        "\n",
        "    Xtr, Ytr, Xva, Yva = train_val_split(X, Y, val_ratio=0.2, seed=42)\n",
        "\n",
        "    # Ativação com limites por saída: [velocidade 1–5, sucção 1–3]\n",
        "    y_min = np.array([1.0, 1.0], dtype=float)\n",
        "    y_max = np.array([5.0, 3.0], dtype=float)\n",
        "    act   = BoundedSigmoid(y_min=y_min, y_max=y_max)\n",
        "\n",
        "    model = MultiOutputPerceptron(n_features=X.shape[1], activation=act, seed=7)\n",
        "    model.fit(\n",
        "        Xtr, Ytr,\n",
        "        lr=0.2, epochs=1500, verbose=verbose,\n",
        "        X_val=Xva, y_val=Yva, patience=80\n",
        "    )\n",
        "\n",
        "    # Avaliação final\n",
        "    tr_mse, tr_mae = model.evaluate(Xtr, Ytr)\n",
        "    va_mse, va_mae = model.evaluate(Xva, Yva)\n",
        "    if verbose:\n",
        "        print(f\"[FINAL] train MSE={tr_mse:.4f}, MAE={tr_mae:.4f} | val MSE={va_mse:.4f}, MAE={va_mae:.4f}\")\n",
        "\n",
        "    # Salvar pesos + metadados\n",
        "    np.savez(\n",
        "        WEIGHTS_PATH,\n",
        "        W=model.W,\n",
        "        y_min=y_min,\n",
        "        y_max=y_max\n",
        "    )\n",
        "    return model, {\"train\": (tr_mse, tr_mae), \"val\": (va_mse, va_mae)}\n",
        "\n",
        "def load_model(path: str = WEIGHTS_PATH) -> MultiOutputPerceptron:\n",
        "    data = np.load(path, allow_pickle=False)\n",
        "    W = data[\"W\"]\n",
        "    y_min = data[\"y_min\"]\n",
        "    y_max = data[\"y_max\"]\n",
        "    act = BoundedSigmoid(y_min=y_min, y_max=y_max)\n",
        "    model = MultiOutputPerceptron(n_features=W.shape[0]-1, activation=act, seed=0)\n",
        "    model.W = W\n",
        "    return model\n",
        "\n",
        "def predict_one(model: MultiOutputPerceptron, floor: str, dirt: float, dist: float) -> Tuple[float, float]:\n",
        "    x = encode_row(floor, dirt, dist)\n",
        "    y = model.predict(x)[0]  # [speed, suction]\n",
        "    v = float(np.clip(y[0], 1.0, 5.0))\n",
        "    p = float(np.clip(y[1], 1.0, 3.0))\n",
        "    return round(v, 2), round(p, 2)\n",
        "\n",
        "\n",
        "\n",
        "# Sanity checks (opcionais)\n",
        "\n",
        "\n",
        "def sanity_checks(model: MultiOutputPerceptron, rng_seed: int = 1) -> None:\n",
        "    rng = np.random.default_rng(rng_seed)\n",
        "\n",
        "    # 1) Faixas\n",
        "    X, _ = make_dataset(n_samples=500, seed=rng.integers(1, 10_000))\n",
        "    Yp = model.predict(X)\n",
        "    assert np.all((Yp[:,0] >= 1.0) & (Yp[:,0] <= 5.0)), \"Velocidade fora de [1,5]\"\n",
        "    assert np.all((Yp[:,1] >= 1.0) & (Yp[:,1] <= 3.0)), \"Sucção fora de [1,3]\"\n",
        "\n",
        "    # 2) Monotonicidade (aproximada) da sucção com sujeira fixa piso/dist\n",
        "    floors = [\"madeira\", \"cerâmica\", \"carpete\"]\n",
        "    for f in floors:\n",
        "        xs = [encode_row(f, d, 5.0) for d in np.linspace(0, 10, 11)]\n",
        "        xs = np.vstack(xs)\n",
        "        ys = model.predict(xs)[:,1]  # sucção\n",
        "        # tolerância: pequenas não-monotonicidades podem ocorrer; checagem frouxa\n",
        "        assert (ys[-1] >= ys[0] - 1e-6), f\"Sucção não cresceu de d=0 para d=10 em {f}\"\n",
        "\n",
        "    # 3) Velocidade aumenta com distância (mantendo sujeira alta)\n",
        "    xs = [encode_row(\"madeira\", 9.0, d) for d in np.linspace(0, 5, 6)]\n",
        "    xs = np.vstack(xs)\n",
        "    vs = model.predict(xs)[:,0]  # velocidade\n",
        "    assert (vs[-1] >= vs[0] - 1e-6), \"Velocidade não aumentou de dist=0 para dist=5\"\n",
        "\n",
        "    print(\"Sanity checks: OK\")\n",
        "\n",
        "\n",
        "\n",
        "# Execução de script\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model, metrics = train_model(verbose=True)\n",
        "\n",
        "    print(\"\\nMétricas (MSE, MAE):\")\n",
        "    print(f\"   Treino: {metrics['train']}\")\n",
        "    print(f\"Validação: {metrics['val']}\")\n",
        "\n",
        "    print(\"\\nDemonstração:\")\n",
        "    scenarios = [\n",
        "        (\"madeira\", 2, 5.0),\n",
        "        (\"cerâmica\", 6, 2.5),\n",
        "        (\"carpete\", 9, 0.5),\n",
        "        (\"carpete\", 3, 5.0),\n",
        "        (\"madeira\", 10, 0.0),\n",
        "        (\"porcelanato\", 7, 4.0),  # alias de cerâmica\n",
        "        (\"wood\", 5, 2.0),         # alias de madeira\n",
        "        (\"carpet\", 8, 1.0),       # alias de carpete\n",
        "    ]\n",
        "    for s in scenarios:\n",
        "        v, p = predict_one(model, *s)\n",
        "        print(f\"Entrada: piso={s[0]}, sujeira={s[1]}, dist={s[2]} m  ->  velocidade={v}  potência={p}\")\n",
        "\n",
        "    print(\"\\nRodando sanity checks...\")\n",
        "    sanity_checks(model)"
      ]
    }
  ]
}