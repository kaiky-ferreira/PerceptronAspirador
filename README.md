# ü§ñ Perceptron ‚Äì Aspirador Inteligente (AI 2025 ‚Ä¢ UNIBH)

**Disciplina:** Intelig√™ncia Artificial ‚Äì Trilha Computa√ß√£o  
**Prof.:** Fabr√≠cio Valadares 

**Local:** Belo Horizonte/MG ‚Äì Centro Universit√°rio de Belo Horizonte UNiBH

---

## üéØ Objetivo da atividade

Projetar e treinar **um perceptron para controlar um aspirador de p√≥ inteligente**.  
O modelo recebe tr√™s entradas (tipo de piso, n√≠vel de sujeira e dist√¢ncia at√© obst√°culos) e retorna **duas sa√≠das cont√≠nuas**:
- **Velocidade do movimento** (faixa: `1` a `5`)
- **Pot√™ncia de suc√ß√£o** (faixa: `1` a `3`)

A proposta segue o enunciado da atividade pr√°tica e inclui **c√≥digo completo, justificativas de projeto, procedimento de execu√ß√£o, exemplos e valida√ß√µes**.

---

## üß© Formula√ß√£o do problema

### Entradas
- **Tipo de piso**: `madeira`, `cer√¢mica`, `carpete` (com *aliases* robustos: `wood`, `laminado`, `porcelanato`, `tile`, `carpet`, etc.)  
  Codifica√ß√£o: **one-hot** com 3 posi√ß√µes.
- **Sujeira**: escala original `0‚Äì10` (o enunciado cita `1‚Äì5`, mas a pr√≥pria base sugerida usa at√© `9`; o c√≥digo aceita `0‚Äì10`).  
  Normaliza√ß√£o para `[0,1]` por *clamp* e divis√£o.
- **Dist√¢ncia do obst√°culo**: `0‚Äì5` metros.  
  Normaliza√ß√£o para `[0,1]` por *clamp* e divis√£o.

> Vetor final de atributos: **5 dimens√µes** ‚Üí `[piso_madeira, piso_cer√¢mica, piso_carpete, sujeira_norm, distancia_norm]`.

### Sa√≠das
- **Velocidade** (`1‚Äì5`)
- **Pot√™ncia** (`1‚Äì3`)

As sa√≠das s√£o tratadas como **vari√°veis cont√≠nuas** (regress√£o) para refletir melhor atuadores reais.

---

## üèóÔ∏è Modelo e escolha da ativa√ß√£o

### Arquitetura
Um **perceptron linear multi‚Äësa√≠da** (duas sa√≠das) com **bias** expl√≠cito e ativa√ß√£o de sa√≠da **sigmoide limitada** (classe `BoundedSigmoid`).  
Pesos: matriz `W` com forma `(features+1, 2)`.

### Por que **sigmoide** (limitada) e n√£o **step**?
- **Step** gera apenas 0/1 (classifica√ß√£o), inadequado para **faixas cont√≠nuas** e controle fino.
- **Sigmoide** permite **gradiente n√£o nulo**, possibilitando **descida de gradiente** com **MSE** e aprendizagem est√°vel.
- A vers√£o **limitada** mapeia diretamente para **intervalos f√≠sicos**:  
  `y = y_min + (y_max ‚àí y_min) * sigmoid(z)`  
  garantindo **velocidade ‚àà [1,5]** e **pot√™ncia ‚àà [1,3]` sem p√≥s-processamento.

**Conclus√£o:** a **sigmoide limitada** √© **a melhor escolha** para este problema de **regress√£o com faixas**.

---

## üß™ Dados e treinamento

### Gera√ß√£o de dados (heur√≠stica‚Äëalvo)
Para treinar com mais variedade, geramos um dataset sint√©tico a partir de **regras f√≠sicas simples**:
- Carpetes pedem **maior suc√ß√£o** e **menor velocidade**.
- Quanto **maior a sujeira**, **maior a suc√ß√£o** e **menor a velocidade**.
- Quanto **maior a dist√¢ncia de obst√°culos**, **maior pode ser a velocidade**.

> Fun√ß√£o: `target_speed_and_suction(...)` produz r√≥tulos cont√≠nuos coerentes nessas faixas.

### Pipeline
- **Normaliza√ß√£o** de entradas em `[0,1]` (sujeira, dist√¢ncia); **one‚Äëhot** para piso.
- **Loss:** MSE
- **Otimiza√ß√£o:** gradiente (taxa `lr=0.2`)
- **Early stopping** com valida√ß√£o hold‚Äëout (`20%`).

### M√©tricas (execu√ß√£o de exemplo)
```
[FINAL] train MSE=0.0070, MAE=0.0586 | val MSE=0.0070, MAE=0.0598
```
> Erro m√©dio absoluto ~**0,06** nas escalas das sa√≠das ‚Üí **controle preciso**.

---

## ‚úÖ Sanity checks (valida√ß√µes autom√°ticas)

A fun√ß√£o `sanity_checks(model)` verifica:
1. **Faixas** de sa√≠da respeitadas: velocidade ‚àà `[1,5]`, pot√™ncia ‚àà `[1,3]`.
2. **Monotonicidade aproximada** da pot√™ncia com sujeira crescente (dist√¢ncia fixa).
3. **Velocidade aumenta com dist√¢ncia** (mantendo sujeira alta).

Esses testes d√£o seguran√ßa de que o modelo aprendeu rela√ß√µes coerentes com o dom√≠nio.

---

## üì¶ Como executar

### Pr√©‚Äërequisitos
- Python **3.10+**
- `numpy`

```bash
# (opcional) criar venv
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

pip install numpy
```

### Rodar treinamento + demonstra√ß√£o
```bash
python main.py
```
Sa√≠das esperadas: logs de √©poca, m√©tricas finais, **demonstra√ß√£o** com cen√°rios de teste (incluindo *aliases* de piso) e execu√ß√£o de **sanity checks**.  
Os **pesos** s√£o salvos em `vacuum_multi.npz`.

### Usar o modelo treinado em outro script
```python
from main import load_model, predict_one
model = load_model("vacuum_multi.npz")
vel, pot = predict_one(model, "carpete", 8, 1.0)
print(vel, pot)
```

---

## üìà B√¥nus ‚Äì Gr√°fico de aprendizagem (training curve)

Para gerar um gr√°fico de **MSE por √©poca**, adicione um *callback* simples no la√ßo de treino e plote com `matplotlib`:

```python
# dentro de MultiOutputPerceptron.fit(...)
history = []
...
for ep in range(epochs):
    ...
    tr_loss = self._mse(y_pred, y_true)
    history.append(tr_loss)
    ...
# depois de treinar:
import matplotlib.pyplot as plt
plt.plot(history)
plt.xlabel("√âpoca")
plt.ylabel("MSE (treino)")
plt.title("Curva de aprendizagem")
plt.show()
```

> Dica: tamb√©m registre `val_loss` para comparar **overfitting** vs **generaliza√ß√£o**.

---

## üóÇÔ∏è Estrutura sugerida do reposit√≥rio

```
.
‚îú‚îÄ main.py                 # (o arquivo com o c√≥digo fornecido)
‚îú‚îÄ vacuum_multi.npz        # pesos salvos ap√≥s o treino (gerado)
‚îú‚îÄ README.md               # este arquivo
‚îî‚îÄ requirements.txt        # opcional: numpy>=1.24
```

**Exemplo de `requirements.txt`:**
```
numpy>=1.24
matplotlib>=3.8  # (se for gerar gr√°fico b√¥nus)
```

---

## üß† Decis√µes de projeto (resumo)

- **Regress√£o cont√≠nua** (controle mais fino) em vez de classifica√ß√£o discreta.
- **Sigmoide limitada por sa√≠da** para impor **restri√ß√µes f√≠sicas** nativamente.
- **Aliases** e **normaliza√ß√£o robusta** (com *clamp*) para entradas seguras.
- **Early stopping** orientado por valida√ß√£o para evitar overfitting.
- **Sanity checks** que testam propriedades desej√°veis do sistema.

---

## üî¨ Limita√ß√µes e pr√≥ximos passos

- **Perceptron linear** capta rela√ß√µes de primeira ordem; intera√ß√µes complexas poderiam se beneficiar de **camadas ocultas** (MLP).
- **Dados sint√©ticos** baseados em heur√≠stica; coletar **telemetria real** do aspirador pode refinar o mapeamento.
- Explorar **regulariza√ß√£o** e **otimizadores** (Adam) e **tuning** de hiperpar√¢metros.
- Implementar **calibra√ß√£o**/quantiza√ß√£o se o alvo for um **microcontrolador**.

---

## üë• Time e cr√©ditos
Projeto desenvolvido conforme a atividade pr√°tica de **IA 2025 ‚Äì UNIBH**.  
**Autores:** Maria Clara Palhares (Mariacpdb), Ka√≠ky (kaiky-ferreira), Yris (YrisSother),Gabriel (ShugZin), Breno Yohan (Gu4xin), Laysa (Laysa-eSerr√£o).

